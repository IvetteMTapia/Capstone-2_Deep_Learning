{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Engineering and Deep Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvetteMTapia/Capstone-2_Deep_Learning/blob/master/Feature_Engineering_and_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "22mhO5tdrfsA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "metadata": {
        "id": "vbeE0-_lltw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import keras\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Activation, Dropout, Concatenate, Input\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ra4wj6SOZE_v",
        "colab_type": "code",
        "outputId": "fd051ab7-6ba6-4e5f-e937-616f9b7ac136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "cell_type": "code",
      "source": [
        "# Create connection to Google Drive to get files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kIeJhDcEr4wi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload Cleaned Data"
      ]
    },
    {
      "metadata": {
        "id": "4tLxy8gQr_nt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Upload 2015 - 2018 AIH cleaned features: demographics, diagnosis and hospitalization. "
      ]
    },
    {
      "metadata": {
        "id": "gpaGMmdsloM6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Proportional Random Sample **"
      ]
    },
    {
      "metadata": {
        "id": "aKKXA8vWOp5W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Path to train data\n",
        "\n",
        "\n",
        "data_path = ('/content/gdrive/My Drive/Deep Learning/AIH_clean_concantenated.csv')\n",
        "\n",
        "cols = ['SEXO_CAT','IDADE','MORTE_CAT','CAP_CAT','UTI_MES_TO','UTI_INT_TO',\n",
        "        'DIAR_ACOM','DIAS_PERM','ESPEC_CAT','PROC_REA_CAT','GRP_CAT',\n",
        "        'COBRANCA_CAT','IND_VDRL_CAT','CAR_INT_CAT','COMPLEX_CAT','MARCA_UTI_CAT',\n",
        "        'DIAG_PRINC_CAT']\n",
        "\n",
        "cols_not_used = ['CAT_CAT','RACA_COR_CAT','ETNIA_CAT','cobranca_group_CAT',\n",
        "                 'CONTRACEP1_CAT','CONTRACEP2_CAT','proc_group_CAT','MUNIC_RES_CAT',\"CAT_CAT\"]\n",
        "\n",
        "#Read to pandas df\n",
        "\n",
        "num_rows = 1000000\n",
        "\n",
        "data = pd.read_csv(data_path, usecols = cols, nrows = num_rows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qYBJP8xhI0hI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Training Data for DNN"
      ]
    },
    {
      "metadata": {
        "id": "maFBbSceMfoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**One-Hot Encode Categorical Predictors - Create Input (X) dataset**"
      ]
    },
    {
      "metadata": {
        "id": "Bf2Zgb7bH73n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "cols_encode = ['SEXO_CAT','MORTE_CAT','CAP_CAT','ESPEC_CAT',\n",
        "               'COBRANCA_CAT','IND_VDRL_CAT','CAR_INT_CAT',\n",
        "               'COMPLEX_CAT','MARCA_UTI_CAT','GRP_CAT'] # columns to one-hot encode\n",
        "\n",
        "pre = ['c1','c2','c3','c4','c5','c6','c7','c8','c9','c10'] # prefixes of one-hot encoded columns\n",
        "\n",
        "one_hot = pd.get_dummies(data, columns= cols_encode, prefix = pre)\n",
        "\n",
        "#Remove Procedure Realized(Y) & Diagnosis Features from input features\n",
        "\n",
        "one_hot.drop(['PROC_REA_CAT', 'DIAG_PRINC_CAT'], axis = 1, inplace=True)\n",
        "\n",
        "X = one_hot.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EvhPPUmBNZwE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create Output Feature - Y**"
      ]
    },
    {
      "metadata": {
        "id": "JiFWvXiU39wj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create Output Feature\n",
        "\n",
        "Y = pd.get_dummies(data.PROC_REA_CAT, prefix = 'proc').values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wQRjZC-p1OKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Split Data into Train, Valid and Testing**"
      ]
    },
    {
      "metadata": {
        "id": "hSM7X7_z1Mgo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First split into training and validation\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=.15, train_size = 0.85, \n",
        "                                                      random_state = 42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nD6bYVmw1Szd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Breakdown further into valid and testing\n",
        "\n",
        "x_valid, x_test, y_valid, y_test = train_test_split(x_valid, y_valid, test_size=.35, train_size = 0.65, \n",
        "                                                    random_state = 42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jzXSHQlU3Fi-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Shape for Each Sample**"
      ]
    },
    {
      "metadata": {
        "id": "kFSf6jau28S-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7da600c-f2a6-4cac-99ba-e13676dd2ae0"
      },
      "cell_type": "code",
      "source": [
        "print('X shape |', 'Train:', x_train.shape, 'Valid:', x_valid.shape, 'Test:',x_test.shape)\n",
        "\n",
        "print('Y shape |', 'Train:', y_train.shape, 'Valid:', y_valid.shape, 'Test:',y_test.shape)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape | Train: (850000, 354) Valid: (97500, 354) Test: (52500, 354)\n",
            "Y shape | Train: (850000, 1612) Valid: (97500, 1612) Test: (52500, 1612)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ws1zp5p427n6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Input Columns\n",
        "\n",
        "input_cols = x_train.shape[1]\n",
        "\n",
        "#Output Columns\n",
        "\n",
        "output_cols = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F3T2y5Ksqess",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network - Baseline Model"
      ]
    },
    {
      "metadata": {
        "id": "hliyHb-bC9c8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model with no regularization"
      ]
    },
    {
      "metadata": {
        "id": "aar1V1Xdqo9J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set Up Model\n",
        "\n",
        "baseline = Sequential()\n",
        "\n",
        "#Input Layers\n",
        "\n",
        "baseline.add(Dense(100, activation='relu', input_shape = (input_cols,)))\n",
        "\n",
        "# Second Layer\n",
        "baseline.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Third Layer\n",
        "baseline.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Fourth Layer\n",
        "baseline.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Fifth Layer\n",
        "baseline.add(Dense(100, activation='relu'))\n",
        "\n",
        "#Outupt Layer\n",
        "\n",
        "baseline.add(Dense(output_cols, activation='softmax'))\n",
        "\n",
        "# Optimizer: Adam Gradient Descent\n",
        "\n",
        "adamgrad = keras.optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
        "\n",
        "#Compile Function\n",
        "baseline.compile(optimizer=adamgrad, \n",
        "                 loss='categorical_crossentropy', \n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='loss', patience=5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5FIrwPBSv58w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2a370a69-b871-4565-e2a1-15d08f25be7b"
      },
      "cell_type": "code",
      "source": [
        "# Fit Model Function\n",
        "\n",
        "%%time\n",
        "\n",
        "baseline.fit(x = x_train, \n",
        "             y = y_train, epochs= 25,\n",
        "             shuffle = True,\n",
        "             batch_size=128,\n",
        "             verbose=2,\n",
        "             callbacks=callbacks)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " - 134s - loss: 2.9497 - acc: 0.4218\n",
            "Epoch 2/2\n",
            " - 135s - loss: 1.9632 - acc: 0.5770\n",
            "CPU times: user 2min 3s, sys: 2min 52s, total: 4min 55s\n",
            "Wall time: 4min 29s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa92b9650f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "NMkcHy6SDx4s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network - Model with Dropout Regularization"
      ]
    },
    {
      "metadata": {
        "id": "Mik_cRLnEPLn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model with dropout regularization"
      ]
    },
    {
      "metadata": {
        "id": "4SFWsXenD8DC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set Up Model\n",
        "\n",
        "model_reg = Sequential()\n",
        "\n",
        "#Input Layers\n",
        "\n",
        "model_reg.add(Dense(100, activation='relu', input_shape = (input_cols,)))\n",
        "model_reg.add(Dropout(0.3))\n",
        "\n",
        "# Second Layer\n",
        "model_reg.add(Dense(100, activation='relu'))\n",
        "model_reg.add(Dropout(0.3))\n",
        "\n",
        "# Third Layer\n",
        "model_reg.add(Dense(100, activation='relu'))\n",
        "model_reg.add(Dropout(0.3))\n",
        "\n",
        "# Fourth Layer\n",
        "model_reg.add(Dense(100, activation='relu'))\n",
        "model_reg.add(Dropout(0.3))\n",
        "\n",
        "# Fifth Layer\n",
        "model_reg.add(Dense(100, activation='relu'))\n",
        "model_reg.add(Dropout(0.3))\n",
        "\n",
        "#Outupt Layer\n",
        "\n",
        "model_reg.add(Dense(output_cols, activation='softmax'))\n",
        "\n",
        "# Optimizer: Adam Gradient Descent\n",
        "\n",
        "adamgrad = keras.optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
        "\n",
        "#Compile Function\n",
        "model_reg.compile(optimizer=adamgrad, \n",
        "                 loss='categorical_crossentropy', \n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='loss', patience=5)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Z6MMJgOD8gl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fit Model Function\n",
        "\n",
        "%%time\n",
        "\n",
        "baseline.fit(x = x_train, \n",
        "             y = y_train, epochs= 25,\n",
        "             shuffle = True,\n",
        "             batch_size=128,\n",
        "             verbose=2,\n",
        "             callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tY_Ujd7UgH5q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model with Embedding Layer"
      ]
    },
    {
      "metadata": {
        "id": "UOVUAjXH8QpV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare Data for Model"
      ]
    },
    {
      "metadata": {
        "id": "EkVLBlvP4oBm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**One-Hot Encode Categorical Predictors - Create Auxiliary Dataset**"
      ]
    },
    {
      "metadata": {
        "id": "2uCalvxE5vJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cols_encode = ['SEXO_CAT','MORTE_CAT','CAP_CAT','ESPEC_CAT',\n",
        "               'COBRANCA_CAT','IND_VDRL_CAT','CAR_INT_CAT',\n",
        "               'COMPLEX_CAT','MARCA_UTI_CAT'] # columns to one-hot encode, GRP_CAT not included\n",
        "\n",
        "pre = ['c1','c2','c3','c4','c5','c6','c7','c8','c9'] # prefixes of one-hot encoded columns\n",
        "\n",
        "one_hot2 = pd.get_dummies(train, columns= cols_encode, prefix = pre)\n",
        "\n",
        "#Remove Procedure Realized(Y) & Diagnosis Features from input features\n",
        "\n",
        "one_hot2.drop('PROC_REA_CAT', 'DIAG_PRINC_CAT', axis = 1,inplace=True)\n",
        "\n",
        "aux = one_hot2.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ezPPND457Fnf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create Categorical Inputs**"
      ]
    },
    {
      "metadata": {
        "id": "0N27ESA058t7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cat_input = train[['PROC_REA_CAT','GRP_CAT']].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sPENaY_U7a83",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Split Data into Train, Valid and Testing**"
      ]
    },
    {
      "metadata": {
        "id": "7Qqd93t76QuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First split into training and validation\n",
        "\n",
        "aux_train, aux_valid, cat_input_train, cat_input_valid = train_test_split(aux, cat_input, \n",
        "                                                                          test_size=.15, train_size = 0.85, \n",
        "                                                                          random_state = 42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2PEMFdJH6RJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Breakdown further into valid and testing\n",
        "\n",
        "aux_valid, aux_test, cat_input_valid, cat_input_test = train_test_split(aux_valid, cat_input_valid, \n",
        "                                                                        test_size=.34, train_size = 0.66, \n",
        "                                                                        random_state = 42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mC2pEF9c9FBD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Shape of Arrays**"
      ]
    },
    {
      "metadata": {
        "id": "n1naSNTz9AtX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('aux shape |', 'Train:', aux_train.shape, 'Valid:', aux_valid.shape, 'Test:',aux_test.shape)\n",
        "\n",
        "print('cat_input shape |', 'Train:', cat_input_train.shape, 'Valid:', cat_input_valid.shape, 'Test:',cat_input_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lHY7VLtJ9EON",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Auxiliary Cols\n",
        "\n",
        "aux_cols = aux_train.shape[1]\n",
        "\n",
        "# Columns\n",
        "\n",
        "cat_input_cols = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2BGICS1gMeWL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Size of Unique Categorical Values (i.e. size of vocab)\n",
        "\n",
        "dim = data['PROC_REA_CAT'].nunique() + data['GRP_CAT'].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OXljxcmd83Uy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> Note: Output stays the same. Will use y_train, y_test and y_valid created above."
      ]
    },
    {
      "metadata": {
        "id": "dQ7jsqyt8VUQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Embedding Layer Model**"
      ]
    },
    {
      "metadata": {
        "id": "jsK0U29rfZtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "79547a7c-b2b9-4941-b03d-b0be6d4dab6d"
      },
      "cell_type": "code",
      "source": [
        "# Categorical Inputs\n",
        "\n",
        "cat_input = Input(shape=(cat_input_cols,), dtype='int32', name='cat_input')\n",
        "\n",
        "# Embedding Layer\n",
        "\n",
        "x = Embedding(output_dim=80, input_dim=dim, input_length=cat_input_cols)(main_input)\n",
        "\n",
        "# A LSTM will transform the vector sequence into a single vector,\n",
        "# containing information about the entire sequence\n",
        "\n",
        "lstm_out = LSTM(32)(x)\n",
        "\n",
        "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
        "\n",
        "#Define auxiliary input layer\n",
        "\n",
        "auxiliary_input = Input(shape=(aux_cols,), name='aux_input')\n",
        "\n",
        "# Add numerical data & One - Hot Encoded Data\n",
        "\n",
        "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
        "\n",
        "# Stack a deep densely-connected network \n",
        "\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "\n",
        "# Output Layer\n",
        "\n",
        "main_output = Dense(output_cols, activation='softmax', name='main_output')(x)\n",
        "\n",
        "# Model\n",
        "\n",
        "embbed_model = Model(inputs=[main_input, auxiliary_input], \n",
        "              outputs=[main_output, auxiliary_output])\n",
        "\n",
        "# Optimizer: Adam Gradient Descent\n",
        "\n",
        "adamgrad = keras.optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
        "\n",
        "#Compile\n",
        "\n",
        "embbed_model.compile(optimizer=adamgrad, \n",
        "                 loss={'main_output':'categorical_crossentropy', \n",
        "                       'aux_output':'binary_crossentropy'},\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-65cf05b26847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_input_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cat_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Embedding Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cat_input_cols' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "tR-vzwNDhDCu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit({'main_input':cat_input_train , 'aux_input':aux_train },\n",
        "          {'main_output':y_train , 'aux_output':auxiliary_output},\n",
        "          epochs=25, batch_size=128,verbose = 2, callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q1AIg-JVj9OY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fit Trainined Models to Test Data"
      ]
    },
    {
      "metadata": {
        "id": "l_uiTjpLyd-8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score_baseline = baseline.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "djHdL7zbFJp8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score_model_reg = model_reg.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mf9ppU-vW6ka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## K-Fold Cross Validation (5-Fold)"
      ]
    },
    {
      "metadata": {
        "id": "iRfJwxxpW934",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Turn this into a function??\n",
        "\n",
        "# Define 5-fold cross validation\n",
        "\n",
        "random_seed = 42\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed )\n",
        "\n",
        "cvscores = []\n",
        "\n",
        "for train, test in kfold.split(x_valid, y_valid):\n",
        "  \n",
        "\t# Fit the model\n",
        "\t\n",
        "  model.fit(x_valid[train], y_valid[train], epochs=150, batch_size=128, verbose=0)\n",
        "  \n",
        "\t# evaluate the model\n",
        "  \n",
        "  scores = model.evaluate(x_valid[test], y_valid[test], batch_size=128, verbose=0)\n",
        "  \n",
        "\tprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  \n",
        "\tcvscores.append(scores[1] * 100)\n",
        "  \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GdjpCeK8GCTO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Notes**\n",
        "\n",
        "\n",
        "\n",
        "*   Test different learning rates\n",
        "*   Modify Architecture\n",
        "*   Other types of regularization?\n",
        "*   Feed more data\n",
        "*   Testing\n",
        "*   K- Fold Cross Validate\n",
        "\n"
      ]
    }
  ]
}