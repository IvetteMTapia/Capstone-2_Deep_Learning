{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Engineering and Deep Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvetteMTapia/Capstone-2_Deep_Learning/blob/master/Feature_Engineering_and_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "22mhO5tdrfsA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "metadata": {
        "id": "vbeE0-_lltw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import keras\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Activation, Dropout, Concatenate, Input, Embedding, LSTM\n",
        "from keras.models import Sequential, Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ra4wj6SOZE_v",
        "colab_type": "code",
        "outputId": "5fac6c6f-e8fa-4691-f468-47b0d039c645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "# Create connection to Google Drive to get files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kIeJhDcEr4wi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload Cleaned Data"
      ]
    },
    {
      "metadata": {
        "id": "4tLxy8gQr_nt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Upload 2015 - 2018 AIH cleaned features: demographics, diagnosis and hospitalization. "
      ]
    },
    {
      "metadata": {
        "id": "aKKXA8vWOp5W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Path to train data\n",
        "\n",
        "\n",
        "data_path = ('/content/gdrive/My Drive/Deep Learning/AIH_clean_concantenated.csv')\n",
        "\n",
        "cols = ['SEXO_CAT','IDADE','MORTE_CAT','CAP_CAT','UTI_MES_TO','UTI_INT_TO',\n",
        "        'DIAR_ACOM','DIAS_PERM','ESPEC_CAT','PROC_REA_CAT','GRP_CAT',\n",
        "        'COBRANCA_CAT','IND_VDRL_CAT','CAR_INT_CAT','COMPLEX_CAT','MARCA_UTI_CAT',\n",
        "        'DIAG_PRINC_CAT']\n",
        "\n",
        "cols_not_used = ['CAT_CAT','RACA_COR_CAT','ETNIA_CAT','cobranca_group_CAT',\n",
        "                 'CONTRACEP1_CAT','CONTRACEP2_CAT','proc_group_CAT','MUNIC_RES_CAT',\"CAT_CAT\"]\n",
        "\n",
        "#Read to pandas df\n",
        "\n",
        "num_rows = 1000000\n",
        "\n",
        "data = pd.read_csv(data_path, usecols = cols, nrows = num_rows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qYBJP8xhI0hI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Training Data for DNN"
      ]
    },
    {
      "metadata": {
        "id": "maFBbSceMfoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**One-Hot Encode Categorical Predictors - Create Input (X) dataset**"
      ]
    },
    {
      "metadata": {
        "id": "Bf2Zgb7bH73n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "cols_encode = ['SEXO_CAT','MORTE_CAT','CAP_CAT','ESPEC_CAT',\n",
        "               'COBRANCA_CAT','IND_VDRL_CAT','CAR_INT_CAT',\n",
        "               'COMPLEX_CAT','MARCA_UTI_CAT','GRP_CAT'] # columns to one-hot encode\n",
        "\n",
        "pre = ['c1','c2','c3','c4','c5','c6','c7','c8','c9','c10'] # prefixes of one-hot encoded columns\n",
        "\n",
        "one_hot = pd.get_dummies(data, columns= cols_encode, prefix = pre)\n",
        "\n",
        "#Remove Procedure Realized(Y) & Diagnosis Features from input features\n",
        "\n",
        "one_hot.drop(['PROC_REA_CAT', 'DIAG_PRINC_CAT'], axis = 1, inplace=True)\n",
        "\n",
        "X = one_hot.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EvhPPUmBNZwE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create Output Feature - Y**"
      ]
    },
    {
      "metadata": {
        "id": "JiFWvXiU39wj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create Output Feature\n",
        "\n",
        "Y = pd.get_dummies(data.PROC_REA_CAT, prefix = 'proc').values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wQRjZC-p1OKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Split Data into Train, Valid and Testing**"
      ]
    },
    {
      "metadata": {
        "id": "hSM7X7_z1Mgo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First split into training and validation\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=.15, train_size = 0.85, \n",
        "                                                      random_state = 42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nD6bYVmw1Szd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Breakdown further into valid and testing\n",
        "\n",
        "x_valid, x_test, y_valid, y_test = train_test_split(x_valid, y_valid, test_size=.35, train_size = 0.65, \n",
        "                                                    random_state = 42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jzXSHQlU3Fi-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Shape for Each Sample**"
      ]
    },
    {
      "metadata": {
        "id": "kFSf6jau28S-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da5a8e75-2bfe-4d05-a131-6d4009aef4b6"
      },
      "cell_type": "code",
      "source": [
        "print('X shape |', 'Train:', x_train.shape, 'Valid:', x_valid.shape, 'Test:',x_test.shape)\n",
        "\n",
        "print('Y shape |', 'Train:', y_train.shape, 'Valid:', y_valid.shape, 'Test:',y_test.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape | Train: (850000, 354) Valid: (97500, 354) Test: (52500, 354)\n",
            "Y shape | Train: (850000, 1612) Valid: (97500, 1612) Test: (52500, 1612)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ws1zp5p427n6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Input Columns\n",
        "\n",
        "input_cols = x_train.shape[1]\n",
        "\n",
        "#Output Columns\n",
        "\n",
        "output_cols = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F3T2y5Ksqess",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network - Baseline Model"
      ]
    },
    {
      "metadata": {
        "id": "hliyHb-bC9c8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model with no regularization"
      ]
    },
    {
      "metadata": {
        "id": "aar1V1Xdqo9J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set Up Model\n",
        "\n",
        "baseline = Sequential()\n",
        "\n",
        "#Input Layers\n",
        "\n",
        "baseline.add(Dense(100, activation='relu', input_shape = (input_cols,)))\n",
        "\n",
        "# Second Layer\n",
        "baseline.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Third Layer\n",
        "baseline.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Fourth Layer\n",
        "baseline.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Fifth Layer\n",
        "baseline.add(Dense(100, activation='relu'))\n",
        "\n",
        "#Outupt Layer\n",
        "\n",
        "baseline.add(Dense(output_cols, activation='softmax'))\n",
        "\n",
        "# Optimizer: Adam Gradient Descent\n",
        "\n",
        "adamgrad = keras.optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
        "\n",
        "#Compile Function\n",
        "baseline.compile(optimizer=adamgrad, \n",
        "                 loss='categorical_crossentropy', \n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='loss', patience=5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5FIrwPBSv58w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "395a0054-2828-451d-c175-7801ff3bb993"
      },
      "cell_type": "code",
      "source": [
        "# Fit Model Function\n",
        "\n",
        "%%time\n",
        "\n",
        "baseline.fit(x = x_train, \n",
        "             y = y_train, epochs= 25,\n",
        "             shuffle = True,\n",
        "             batch_size=128,\n",
        "             verbose=2,\n",
        "             callbacks=callbacks)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            " - 139s - loss: 3.0064 - acc: 0.4068\n",
            "Epoch 2/25\n",
            " - 143s - loss: 1.9861 - acc: 0.5714\n",
            "Epoch 3/25\n",
            " - 142s - loss: 1.7573 - acc: 0.6020\n",
            "Epoch 4/25\n",
            " - 150s - loss: 1.6483 - acc: 0.6166\n",
            "Epoch 5/25\n",
            " - 145s - loss: 1.5828 - acc: 0.6249\n",
            "Epoch 6/25\n",
            " - 148s - loss: 1.5363 - acc: 0.6300\n",
            "Epoch 7/25\n",
            " - 147s - loss: 1.5008 - acc: 0.6350\n",
            "Epoch 8/25\n",
            " - 148s - loss: 1.4726 - acc: 0.6383\n",
            "Epoch 9/25\n",
            " - 149s - loss: 1.4496 - acc: 0.6407\n",
            "Epoch 10/25\n",
            " - 148s - loss: 1.4304 - acc: 0.6427\n",
            "Epoch 11/25\n",
            " - 149s - loss: 1.4140 - acc: 0.6448\n",
            "Epoch 12/25\n",
            " - 148s - loss: 1.3995 - acc: 0.6467\n",
            "Epoch 13/25\n",
            " - 149s - loss: 1.3869 - acc: 0.6484\n",
            "Epoch 14/25\n",
            " - 150s - loss: 1.3757 - acc: 0.6503\n",
            "Epoch 15/25\n",
            " - 144s - loss: 1.3656 - acc: 0.6515\n",
            "Epoch 16/25\n",
            " - 149s - loss: 1.3564 - acc: 0.6529\n",
            "Epoch 17/25\n",
            " - 151s - loss: 1.3480 - acc: 0.6542\n",
            "Epoch 18/25\n",
            " - 147s - loss: 1.3402 - acc: 0.6552\n",
            "Epoch 19/25\n",
            " - 149s - loss: 1.3332 - acc: 0.6563\n",
            "Epoch 20/25\n",
            " - 149s - loss: 1.3266 - acc: 0.6572\n",
            "Epoch 21/25\n",
            " - 147s - loss: 1.3206 - acc: 0.6579\n",
            "Epoch 22/25\n",
            " - 148s - loss: 1.3149 - acc: 0.6585\n",
            "Epoch 23/25\n",
            " - 146s - loss: 1.3096 - acc: 0.6590\n",
            "Epoch 24/25\n",
            " - 144s - loss: 1.3046 - acc: 0.6600\n",
            "Epoch 25/25\n",
            " - 150s - loss: 1.3000 - acc: 0.6604\n",
            "CPU times: user 24min 7s, sys: 42min 6s, total: 1h 6min 13s\n",
            "Wall time: 1h 1min 20s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b384e0630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "NMkcHy6SDx4s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network - Model with Dropout Regularization"
      ]
    },
    {
      "metadata": {
        "id": "Mik_cRLnEPLn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model with dropout regularization"
      ]
    },
    {
      "metadata": {
        "id": "4SFWsXenD8DC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set Up Model\n",
        "\n",
        "model_reg = Sequential()\n",
        "\n",
        "#Input Layers\n",
        "\n",
        "model_reg.add(Dense(100, activation='relu', input_shape = (input_cols,)))\n",
        "model_reg.add(Dropout(0.3))\n",
        "\n",
        "# Second Layer\n",
        "model_reg.add(Dense(100, activation='relu'))\n",
        "model_reg.add(Dropout(0.3))\n",
        "\n",
        "# Third Layer\n",
        "model_reg.add(Dense(100, activation='relu'))\n",
        "model_reg.add(Dropout(0.3))\n",
        "\n",
        "# Fourth Layer\n",
        "model_reg.add(Dense(100, activation='relu'))\n",
        "model_reg.add(Dropout(0.3))\n",
        "\n",
        "# Fifth Layer\n",
        "model_reg.add(Dense(100, activation='relu'))\n",
        "model_reg.add(Dropout(0.3))\n",
        "\n",
        "#Outupt Layer\n",
        "\n",
        "model_reg.add(Dense(output_cols, activation='softmax'))\n",
        "\n",
        "# Optimizer: Adam Gradient Descent\n",
        "\n",
        "adamgrad = keras.optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
        "\n",
        "#Compile Function\n",
        "model_reg.compile(optimizer=adamgrad, \n",
        "                 loss='categorical_crossentropy', \n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='loss', patience=5)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Z6MMJgOD8gl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "56ccf508-b9a6-4fc9-829b-97edc76e41cd"
      },
      "cell_type": "code",
      "source": [
        "# Fit Model Function\n",
        "\n",
        "%%time\n",
        "\n",
        "baseline.fit(x = x_train, \n",
        "             y = y_train, epochs= 25,\n",
        "             shuffle = True,\n",
        "             batch_size=128,\n",
        "             verbose=2,\n",
        "             callbacks=callbacks)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            " - 145s - loss: 1.2956 - acc: 0.6611\n",
            "Epoch 2/25\n",
            " - 147s - loss: 1.2916 - acc: 0.6616\n",
            "Epoch 3/25\n",
            " - 150s - loss: 1.2877 - acc: 0.6621\n",
            "Epoch 4/25\n",
            " - 145s - loss: 1.2841 - acc: 0.6628\n",
            "Epoch 5/25\n",
            " - 149s - loss: 1.2807 - acc: 0.6632\n",
            "Epoch 6/25\n",
            " - 146s - loss: 1.2775 - acc: 0.6637\n",
            "Epoch 7/25\n",
            " - 148s - loss: 1.2744 - acc: 0.6641\n",
            "Epoch 8/25\n",
            " - 151s - loss: 1.2715 - acc: 0.6646\n",
            "Epoch 9/25\n",
            " - 146s - loss: 1.2687 - acc: 0.6650\n",
            "Epoch 10/25\n",
            " - 145s - loss: 1.2660 - acc: 0.6653\n",
            "Epoch 11/25\n",
            " - 146s - loss: 1.2634 - acc: 0.6655\n",
            "Epoch 12/25\n",
            " - 145s - loss: 1.2610 - acc: 0.6660\n",
            "Epoch 13/25\n",
            " - 146s - loss: 1.2586 - acc: 0.6663\n",
            "Epoch 14/25\n",
            " - 145s - loss: 1.2565 - acc: 0.6665\n",
            "Epoch 15/25\n",
            " - 144s - loss: 1.2543 - acc: 0.6669\n",
            "Epoch 16/25\n",
            " - 147s - loss: 1.2522 - acc: 0.6671\n",
            "Epoch 17/25\n",
            " - 146s - loss: 1.2503 - acc: 0.6675\n",
            "Epoch 18/25\n",
            " - 146s - loss: 1.2483 - acc: 0.6678\n",
            "Epoch 19/25\n",
            " - 147s - loss: 1.2465 - acc: 0.6680\n",
            "Epoch 20/25\n",
            " - 134s - loss: 1.2447 - acc: 0.6681\n",
            "Epoch 21/25\n",
            " - 146s - loss: 1.2430 - acc: 0.6684\n",
            "Epoch 22/25\n",
            " - 143s - loss: 1.2414 - acc: 0.6686\n",
            "Epoch 23/25\n",
            " - 144s - loss: 1.2398 - acc: 0.6688\n",
            "Epoch 24/25\n",
            " - 146s - loss: 1.2383 - acc: 0.6689\n",
            "Epoch 25/25\n",
            " - 122s - loss: 1.2368 - acc: 0.6691\n",
            "CPU times: user 23min 58s, sys: 41min 15s, total: 1h 5min 13s\n",
            "Wall time: 1h 18s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b77de5f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "tY_Ujd7UgH5q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model with Embedding Layer"
      ]
    },
    {
      "metadata": {
        "id": "UOVUAjXH8QpV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare Data for Model"
      ]
    },
    {
      "metadata": {
        "id": "EkVLBlvP4oBm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**One-Hot Encode Categorical Predictors - Create Auxiliary Dataset**"
      ]
    },
    {
      "metadata": {
        "id": "2uCalvxE5vJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cols_encode = ['SEXO_CAT','MORTE_CAT','CAP_CAT','ESPEC_CAT',\n",
        "               'COBRANCA_CAT','IND_VDRL_CAT','CAR_INT_CAT',\n",
        "               'COMPLEX_CAT','MARCA_UTI_CAT'] # columns to one-hot encode, GRP_CAT not included\n",
        "\n",
        "pre = ['c1','c2','c3','c4','c5','c6','c7','c8','c9'] # prefixes of one-hot encoded columns\n",
        "\n",
        "one_hot2 = pd.get_dummies(data, columns= cols_encode, prefix = pre)\n",
        "\n",
        "#Remove Procedure Realized(Y) & Diagnosis Features from input features\n",
        "\n",
        "one_hot2.drop(['PROC_REA_CAT', 'DIAG_PRINC_CAT'], axis = 1,inplace=True)\n",
        "\n",
        "aux = one_hot2.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ezPPND457Fnf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create Categorical Inputs**"
      ]
    },
    {
      "metadata": {
        "id": "0N27ESA058t7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cat_input = data[['PROC_REA_CAT','GRP_CAT']].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sPENaY_U7a83",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Split Data into Train, Valid and Testing**"
      ]
    },
    {
      "metadata": {
        "id": "7Qqd93t76QuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First split into training and validation\n",
        "\n",
        "aux_train, aux_valid, cat_input_train, cat_input_valid = train_test_split(aux, cat_input, \n",
        "                                                                          test_size=.15, train_size = 0.85, \n",
        "                                                                          random_state = 42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2PEMFdJH6RJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Breakdown further into valid and testing\n",
        "\n",
        "aux_valid, aux_test, cat_input_valid, cat_input_test = train_test_split(aux_valid, cat_input_valid, \n",
        "                                                                        test_size=.35, train_size = 0.65, \n",
        "                                                                        random_state = 42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mC2pEF9c9FBD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Shape of Arrays**"
      ]
    },
    {
      "metadata": {
        "id": "n1naSNTz9AtX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b5a19659-178f-4f10-ee17-358818736eb3"
      },
      "cell_type": "code",
      "source": [
        "print('aux shape |', 'Train:', aux_train.shape, 'Valid:', aux_valid.shape, 'Test:',aux_test.shape)\n",
        "\n",
        "print('cat_input shape |', 'Train:', cat_input_train.shape, 'Valid:', cat_input_valid.shape, 'Test:',cat_input_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aux shape | Train: (850000, 97) Valid: (97500, 97) Test: (52500, 97)\n",
            "cat_input shape | Train: (850000, 2) Valid: (97500, 2) Test: (52500, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lHY7VLtJ9EON",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Auxiliary Cols\n",
        "\n",
        "aux_cols = aux_train.shape[1]\n",
        "\n",
        "# Columns\n",
        "\n",
        "cat_input_cols = cat_input_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2BGICS1gMeWL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Size of Unique Categorical Values (i.e. size of vocab)\n",
        "\n",
        "dim = data['PROC_REA_CAT'].nunique() + data['GRP_CAT'].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OXljxcmd83Uy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> Note: Output stays the same. Will use y_train, y_test and y_valid created above."
      ]
    },
    {
      "metadata": {
        "id": "dQ7jsqyt8VUQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Embedding Layer Model**"
      ]
    },
    {
      "metadata": {
        "id": "jsK0U29rfZtS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Categorical Inputs\n",
        "\n",
        "cat_input = Input(shape=(cat_input_cols,), dtype='int32', name='cat_input')\n",
        "\n",
        "# Embedding Layer\n",
        "\n",
        "x = Embedding(output_dim=80, input_dim=dim, input_length=cat_input_cols)(cat_input)\n",
        "\n",
        "# A LSTM will transform the vector sequence into a single vector,\n",
        "# containing information about the entire sequence\n",
        "\n",
        "lstm_out = LSTM(32)(x)\n",
        "\n",
        "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)\n",
        "\n",
        "#Define auxiliary input layer\n",
        "\n",
        "auxiliary_input = Input(shape=(aux_cols,), name='aux_input')\n",
        "\n",
        "# Add numerical data & One - Hot Encoded Data\n",
        "\n",
        "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
        "\n",
        "# Stack a deep densely-connected network \n",
        "\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "\n",
        "# Output Layer\n",
        "\n",
        "main_output = Dense(output_cols, activation='softmax', name='main_output')(x)\n",
        "\n",
        "# Model\n",
        "\n",
        "embbed_model = Model(inputs=[cat_input, auxiliary_input], \n",
        "                     outputs=[main_output, auxiliary_output])\n",
        "\n",
        "# Optimizer: Adam Gradient Descent\n",
        "\n",
        "adamgrad = keras.optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
        "\n",
        "#Compile\n",
        "\n",
        "embbed_model.compile(optimizer=adamgrad, \n",
        "                 loss={'main_output':'categorical_crossentropy', \n",
        "                       'aux_output':'binary_crossentropy'},\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='loss', patience=5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tR-vzwNDhDCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "bb1de79e-4e8b-4abb-c079-fa26274bdde7"
      },
      "cell_type": "code",
      "source": [
        "embbed_model.fit({'cat_input':cat_input_train , 'aux_input':aux_train },\n",
        "          {'main_output':y_train , 'aux_output':auxiliary_output},\n",
        "          epochs=1, batch_size=128,verbose = 2, callbacks=callbacks)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-94166e3f59ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m embbed_model.fit({'cat_input':cat_input_train , 'aux_input':aux_train },\n\u001b[1;32m      2\u001b[0m           \u001b[0;34m{\u001b[0m\u001b[0;34m'main_output'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'aux_output'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mauxiliary_output\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=1, batch_size=128,verbose = 2, callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;34m'When feeding symbolic tensors to a model, we expect the'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;34m'tensors to have a static batch size. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 'Got tensor with shape: %s' % str(shape))\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: When feeding symbolic tensors to a model, we expect thetensors to have a static batch size. Got tensor with shape: (None, 1)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Q1AIg-JVj9OY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fit Trainined Models to Test Data"
      ]
    },
    {
      "metadata": {
        "id": "l_uiTjpLyd-8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score_baseline = baseline.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "djHdL7zbFJp8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score_model_reg = model_reg.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mf9ppU-vW6ka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## K-Fold Cross Validation (5-Fold)"
      ]
    },
    {
      "metadata": {
        "id": "iRfJwxxpW934",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Turn this into a function??\n",
        "\n",
        "# Define 5-fold cross validation\n",
        "\n",
        "random_seed = 42\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed )\n",
        "\n",
        "cvscores = []\n",
        "\n",
        "for train, test in kfold.split(x_valid, y_valid):\n",
        "  \n",
        "\t# Fit the model\n",
        "\t\n",
        "  model.fit(x_valid[train], y_valid[train], epochs=150, batch_size=128, verbose=0)\n",
        "  \n",
        "\t# evaluate the model\n",
        "  \n",
        "  scores = model.evaluate(x_valid[test], y_valid[test], batch_size=128, verbose=0)\n",
        "  \n",
        "\tprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  \n",
        "\tcvscores.append(scores[1] * 100)\n",
        "  \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GdjpCeK8GCTO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Notes**\n",
        "\n",
        "\n",
        "\n",
        "*   Test different learning rates\n",
        "*   Modify Architecture\n",
        "*   Other types of regularization?\n",
        "*   Feed more data\n",
        "*   Testing\n",
        "*   K- Fold Cross Validate\n",
        "\n"
      ]
    }
  ]
}