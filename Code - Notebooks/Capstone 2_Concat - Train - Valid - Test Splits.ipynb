{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Cleaned Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demographic Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 s, sys: 2 s, total: 18.1 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "demo_path = ('/Users/ivettetapia 1/Symbolic Link Seagate Drive/Springboard/Capstone 2_Deep_Learning/Data/AIH_sample_demo.csv')\n",
    "\n",
    "demo_cols = ['MUNIC_RES_CAT','SEXO_CAT','RACA_COR_CAT','ETNIA_CAT','IDADE',\"MORTE_CAT\"]\n",
    "\n",
    "\n",
    "demo_data = pd.read_csv(demo_path, \n",
    "                        encoding = 'UTF-8', \n",
    "                        na_values= ['NaN',' ',''],\n",
    "                        usecols = demo_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16614830 entries, 0 to 16614829\n",
      "Data columns (total 6 columns):\n",
      "MUNIC_RES_CAT    16462037 non-null float64\n",
      "SEXO_CAT         16614830 non-null int64\n",
      "RACA_COR_CAT     12299845 non-null float64\n",
      "ETNIA_CAT        35012 non-null float64\n",
      "IDADE            16614830 non-null int64\n",
      "MORTE_CAT        16614830 non-null int64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 760.6 MB\n"
     ]
    }
   ],
   "source": [
    "demo_data.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diagnosis Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.7 s, sys: 2.95 s, total: 31.7 s\n",
      "Wall time: 32.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diag_path = ('/Users/ivettetapia 1/Symbolic Link Seagate Drive/Springboard/Capstone 2_Deep_Learning/Data/AIH_sample_diag.csv')\n",
    "\n",
    "diag_cols = [\"DIAG_PRINC_CAT\",\"CAT_CAT\",\"CAP_CAT\",\"GRP_CAT\"]\n",
    "\n",
    "\n",
    "diag_data = pd.read_csv(diag_path, \n",
    "                        encoding = 'UTF-8', \n",
    "                        na_values= ['NaN',' ',''],\n",
    "                        usecols = diag_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16614830 entries, 0 to 16614829\n",
      "Data columns (total 4 columns):\n",
      "DIAG_PRINC_CAT    16614830 non-null int64\n",
      "CAT_CAT           16614830 non-null int64\n",
      "CAP_CAT           16614830 non-null int64\n",
      "GRP_CAT           16614830 non-null int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 507.0 MB\n"
     ]
    }
   ],
   "source": [
    "diag_data.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hospitalization Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.8 s, sys: 10.4 s, total: 1min 8s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hospi_path = ('/Users/ivettetapia 1/Symbolic Link Seagate Drive/Springboard/Capstone 2_Deep_Learning/Data/AIH_sample_hospi.csv')\n",
    "\n",
    "hospi_cols = ['ESPEC_CAT', 'CGC_HOSP_CAT', 'UTI_MES_TO',\n",
    "              'MARCA_UTI_CAT','UTI_INT_TO','DIAR_ACOM','DIAS_PERM',\n",
    "              'PROC_REA_CAT','proc_group_CAT','proc_subgroup_CAT','COBRANCA_CAT',\n",
    "              'cobranca_group_CAT','IND_VDRL_CAT','CAR_INT_CAT','CONTRACEP1_CAT',\n",
    "              'CONTRACEP2_CAT','COMPLEX_CAT']\n",
    "\n",
    "\n",
    "hospi_data = pd.read_csv(hospi_path, \n",
    "                         encoding = 'UTF-8', \n",
    "                         na_values= ['NaN',' ',''],\n",
    "                         usecols = hospi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16614830 entries, 0 to 16614829\n",
      "Data columns (total 17 columns):\n",
      "ESPEC_CAT             16614830 non-null int64\n",
      "CGC_HOSP_CAT          16614830 non-null int64\n",
      "UTI_MES_TO            16614830 non-null int64\n",
      "MARCA_UTI_CAT         16614830 non-null int64\n",
      "UTI_INT_TO            16614830 non-null int64\n",
      "DIAR_ACOM             16614830 non-null int64\n",
      "DIAS_PERM             16614830 non-null int64\n",
      "PROC_REA_CAT          16614830 non-null int64\n",
      "proc_group_CAT        16614830 non-null int64\n",
      "proc_subgroup_CAT     16614830 non-null int64\n",
      "COBRANCA_CAT          16614830 non-null int64\n",
      "cobranca_group_CAT    16614830 non-null int64\n",
      "IND_VDRL_CAT          16614830 non-null int64\n",
      "CAR_INT_CAT           16614830 non-null int64\n",
      "CONTRACEP1_CAT        16614830 non-null int64\n",
      "CONTRACEP2_CAT        16614830 non-null int64\n",
      "COMPLEX_CAT           16614830 non-null int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "hospi_data.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate demographics and diagnosis data\n",
    "\n",
    "join_1 = demo_data.join(diag_data, lsuffix='l_', rsuffix='r',  sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate demographics, diagnosis and hospitalization data\n",
    "\n",
    "join_2 = join_1.join(hospi_data, lsuffix='l_', rsuffix='r',  sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_join = join_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16614830 entries, 0 to 16614829\n",
      "Data columns (total 27 columns):\n",
      "MUNIC_RES_CAT         16462037 non-null float64\n",
      "SEXO_CAT              16614830 non-null int64\n",
      "RACA_COR_CAT          12299845 non-null float64\n",
      "ETNIA_CAT             35012 non-null float64\n",
      "IDADE                 16614830 non-null int64\n",
      "MORTE_CAT             16614830 non-null int64\n",
      "DIAG_PRINC_CAT        16614830 non-null int64\n",
      "CAT_CAT               16614830 non-null int64\n",
      "CAP_CAT               16614830 non-null int64\n",
      "GRP_CAT               16614830 non-null int64\n",
      "ESPEC_CAT             16614830 non-null int64\n",
      "CGC_HOSP_CAT          16614830 non-null int64\n",
      "UTI_MES_TO            16614830 non-null int64\n",
      "MARCA_UTI_CAT         16614830 non-null int64\n",
      "UTI_INT_TO            16614830 non-null int64\n",
      "DIAR_ACOM             16614830 non-null int64\n",
      "DIAS_PERM             16614830 non-null int64\n",
      "PROC_REA_CAT          16614830 non-null int64\n",
      "proc_group_CAT        16614830 non-null int64\n",
      "proc_subgroup_CAT     16614830 non-null int64\n",
      "COBRANCA_CAT          16614830 non-null int64\n",
      "cobranca_group_CAT    16614830 non-null int64\n",
      "IND_VDRL_CAT          16614830 non-null int64\n",
      "CAR_INT_CAT           16614830 non-null int64\n",
      "CONTRACEP1_CAT        16614830 non-null int64\n",
      "CONTRACEP2_CAT        16614830 non-null int64\n",
      "COMPLEX_CAT           16614830 non-null int64\n",
      "dtypes: float64(3), int64(24)\n",
      "memory usage: 3.3 GB\n"
     ]
    }
   ],
   "source": [
    "final_join.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-scale continuous values (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "final_join[['IDADE','UTI_MES_TO','UTI_INT_TO','DIAR_ACOM','DIAS_PERM']] = scaler.fit_transform(final_join[['IDADE','UTI_MES_TO','UTI_INT_TO','DIAR_ACOM','DIAS_PERM']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDADE</th>\n",
       "      <th>UTI_MES_TO</th>\n",
       "      <th>UTI_INT_TO</th>\n",
       "      <th>DIAR_ACOM</th>\n",
       "      <th>DIAS_PERM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.661483e+07</td>\n",
       "      <td>1.661483e+07</td>\n",
       "      <td>1.661483e+07</td>\n",
       "      <td>1.661483e+07</td>\n",
       "      <td>1.661483e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.016778e-01</td>\n",
       "      <td>1.527763e-03</td>\n",
       "      <td>2.167705e-04</td>\n",
       "      <td>5.723171e-03</td>\n",
       "      <td>1.481481e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.439140e-01</td>\n",
       "      <td>9.580400e-03</td>\n",
       "      <td>4.061263e-03</td>\n",
       "      <td>1.289579e-02</td>\n",
       "      <td>2.204041e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.121212e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.494505e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.636364e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.241758e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.959596e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.882353e-03</td>\n",
       "      <td>1.648352e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              IDADE    UTI_MES_TO    UTI_INT_TO     DIAR_ACOM     DIAS_PERM\n",
       "count  1.661483e+07  1.661483e+07  1.661483e+07  1.661483e+07  1.661483e+07\n",
       "mean   4.016778e-01  1.527763e-03  2.167705e-04  5.723171e-03  1.481481e-02\n",
       "std    2.439140e-01  9.580400e-03  4.061263e-03  1.289579e-02  2.204041e-02\n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n",
       "25%    2.121212e-01  0.000000e+00  0.000000e+00  0.000000e+00  5.494505e-03\n",
       "50%    3.636364e-01  0.000000e+00  0.000000e+00  0.000000e+00  8.241758e-03\n",
       "75%    5.959596e-01  0.000000e+00  0.000000e+00  5.882353e-03  1.648352e-02\n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_join[['IDADE','UTI_MES_TO','UTI_INT_TO','DIAR_ACOM','DIAS_PERM']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output cleaned concanetaned file as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Concatenated to CSV\n",
    "\n",
    "final_join.to_csv('AIH_clean_concantenated.csv', index = False,\n",
    "                  na_rep= 'NaN', encoding='utf-8', chunksize = 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for DNN - With Principal Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will prepare the training, validation and test data for the neural network. The data will be outputted as Numpy arrays to decrease computational cost in the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Concatenated and Cleaned Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Cleaned Concatenated Data\n",
    "\n",
    "data_path = ('/Users/ivettetapia 1/Symbolic Link Seagate Drive/Springboard/Capstone 2_Deep_Learning/Data/AIH_clean_concantenated.csv')\n",
    "\n",
    "cols = ['SEXO_CAT','IDADE','MORTE_CAT','UTI_MES_TO','UTI_INT_TO','DIAR_ACOM',\n",
    "        'DIAS_PERM','ESPEC_CAT','DIAG_PRINC_CAT','proc_subgroup_CAT',\n",
    "        'COBRANCA_CAT','IND_VDRL_CAT','CAR_INT_CAT','COMPLEX_CAT','MARCA_UTI_CAT']\n",
    "\n",
    "data = pd.read_csv(data_path, \n",
    "                   encoding = 'UTF-8', \n",
    "                   na_values= ['NaN',' ',''],\n",
    "                   usecols = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Feature Arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = data[['SEXO_CAT','MORTE_CAT','IDADE','UTI_MES_TO','IND_VDRL_CAT',\n",
    "              'UTI_INT_TO','DIAR_ACOM','DIAS_PERM','ESPEC_CAT']].values\n",
    "\n",
    "\n",
    "cat = data[['DIAG_PRINC_CAT','ESPEC_CAT','COBRANCA_CAT','CAR_INT_CAT','COMPLEX_CAT','MARCA_UTI_CAT']].values\n",
    "\n",
    "out = pd.get_dummies(data.proc_subgroup_CAT, prefix = 'proc').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9085"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of Unique Categorical Values (i.e. size of vocab)\n",
    "\n",
    "dim = data['DIAG_PRINC_CAT'].nunique() + data['ESPEC_CAT'].nunique() + data['COBRANCA_CAT'].nunique() + data['COMPLEX_CAT'].nunique() + data['MARCA_UTI_CAT'].nunique() + data['CAR_INT_CAT'].nunique()\n",
    "\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Training, Validation and Test Splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split into training and validation\n",
    "\n",
    "num_train, num_valid, cat_train, cat_valid, out_train, out_valid = train_test_split(num, cat, out, \n",
    "                                                                                    test_size=.12, train_size = 0.88, \n",
    "                                                                                    random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown further into valid and testing\n",
    "\n",
    "num_valid, num_test, cat_valid, cat_test, out_valid, out_test = train_test_split(num_valid, cat_valid, out_valid, \n",
    "                                                                                 test_size=.16, train_size = 0.84, \n",
    "                                                                                 random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_input shape | Train: (14621050, 9) Valid: (1674775, 9) Test: (319005, 9)\n",
      "cat_input shape | Train: (14621050, 6) Valid: (1674775, 6) Test: (319005, 6)\n",
      "out_input shape | Train: (14621050, 38) Valid: (1674775, 38) Test: (319005, 38)\n"
     ]
    }
   ],
   "source": [
    "print('num_input shape |', 'Train:',num_train.shape,'Valid:',num_valid.shape,'Test:',num_test.shape)\n",
    "\n",
    "print('cat_input shape |', 'Train:',cat_train.shape,'Valid:',cat_valid.shape,'Test:',cat_test.shape)\n",
    "\n",
    "print('out_input shape |', 'Train:',out_train.shape,'Valid:',out_valid.shape,'Test:',out_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as Numpy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('num_train.npy', num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cat_train.npy', cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('out_train.npy', out_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('num_valid.npy', num_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cat_valid.npy', cat_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('out_valid.npy', out_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('num_test.npy', num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cat_test.npy', cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('out_test.npy', out_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for DNN - With Principal Diagnosis Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will prepare the training, validation and test data for the neural network. The data will be outputted as Numpy arrays to decrease computational cost in the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Concatenated and Cleaned Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Cleaned Concatenated Data\n",
    "\n",
    "data_path = ('/Users/ivettetapia 1/Symbolic Link Seagate Drive/Springboard/Capstone 2_Deep_Learning/Data/AIH_clean_concantenated.csv')\n",
    "\n",
    "cols = ['SEXO_CAT','IDADE','MORTE_CAT','UTI_MES_TO','UTI_INT_TO','DIAR_ACOM',\n",
    "        'DIAS_PERM','ESPEC_CAT','GRP_CAT','proc_subgroup_CAT',\n",
    "        'COBRANCA_CAT','IND_VDRL_CAT','CAR_INT_CAT','COMPLEX_CAT','MARCA_UTI_CAT']\n",
    "\n",
    "data = pd.read_csv(data_path, \n",
    "                   encoding = 'UTF-8', \n",
    "                   na_values= ['NaN',' ',''],\n",
    "                   usecols = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Feature Arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = data[['SEXO_CAT','MORTE_CAT','IDADE','UTI_MES_TO','IND_VDRL_CAT',\n",
    "              'UTI_INT_TO','DIAR_ACOM','DIAS_PERM','ESPEC_CAT']].values\n",
    "\n",
    "\n",
    "cat = data[['GRP_CAT','ESPEC_CAT','COBRANCA_CAT','CAR_INT_CAT','COMPLEX_CAT','MARCA_UTI_CAT']].values\n",
    "\n",
    "out = pd.get_dummies(data.proc_subgroup_CAT, prefix = 'proc').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of Unique Categorical Values (i.e. size of vocab)\n",
    "\n",
    "dim = data['GRP_CAT'].nunique() + data['ESPEC_CAT'].nunique() + data['COBRANCA_CAT'].nunique() + data['COMPLEX_CAT'].nunique() + data['MARCA_UTI_CAT'].nunique() + data['CAR_INT_CAT'].nunique()\n",
    "\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Training, Validation and Test Splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split into training and validation\n",
    "\n",
    "num_train_grp, num_valid_grp, cat_train_grp, cat_valid_grp, out_train_grp, out_valid_grp = train_test_split(num, cat, out, \n",
    "                                                                                    test_size=.12, train_size = 0.88, \n",
    "                                                                                    random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown further into valid and testing\n",
    "\n",
    "num_valid_grp, num_test_grp, cat_valid_grp, cat_test_grp, out_valid_grp, out_test_grp = train_test_split(num_valid, cat_valid, out_valid, \n",
    "                                                                                 test_size=.16, train_size = 0.84, \n",
    "                                                                                 random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_input shape | Train: (14621050, 9) Valid: (1406811, 9) Test: (267964, 9)\n",
      "cat_input shape | Train: (14621050, 6) Valid: (1406811, 6) Test: (267964, 6)\n",
      "out_input shape | Train: (14621050, 38) Valid: (1406811, 38) Test: (267964, 38)\n"
     ]
    }
   ],
   "source": [
    "print('num_input shape |', 'Train:',num_train_grp.shape,'Valid:',num_valid_grp.shape,'Test:',num_test_grp.shape)\n",
    "\n",
    "print('cat_input shape |', 'Train:',cat_train_grp.shape,'Valid:',cat_valid_grp.shape,'Test:',cat_test_grp.shape)\n",
    "\n",
    "print('out_input shape |', 'Train:',out_train_grp.shape,'Valid:',out_valid_grp.shape,'Test:',out_test_grp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as Numpy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('num_train_grp.npy', num_train_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cat_train_grp.npy', cat_train_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('out_train_grp.npy', out_train_grp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('num_valid_grp.npy', num_valid_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cat_valid_grp.npy', cat_valid_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('out_valid_grp.npy', out_valid_grp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('num_test_grp.npy', num_test_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cat_test_grp.npy', cat_test_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('out_test_grp.npy', out_test_grp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
